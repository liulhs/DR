{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jason/anaconda3/envs/coursistant/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "from typing import Any, Dict, List, Optional\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "from llama_index.core.query_pipeline import QueryPipeline, InputComponent, ArgPackComponent\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.postprocessor.colbert_rerank import ColbertRerank\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.core.query_pipeline import CustomQueryComponent\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "from pydantic import BaseModel\n",
    "from llama_index.core.bridge.pydantic import Field\n",
    "from llama_index.core.output_parsers import PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "\n",
    "class AnswerFormat(BaseModel):\n",
    "    \"\"\"Object representing a single knowledge pdf file.\"\"\"\n",
    "    answer: str = \"None\"\n",
    "    file_name: str = \"None\"\n",
    "    page_number: int = 0\n",
    "\n",
    "    @classmethod\n",
    "    def schema(cls, by_alias: bool = True) -> Dict[str, Any]:\n",
    "        schema = super().model_json_schema(by_alias)\n",
    "        properties = schema.get(\"properties\", {})\n",
    "\n",
    "        # Manually adding descriptions\n",
    "        properties[\"answer\"][\"description\"] = \"Your Answer to the given query\"\n",
    "        properties[\"file_name\"][\"description\"] = \"PDF file's file name where the answer can be found, fill in with empty string if you couldn't find it\"\n",
    "        properties[\"page_number\"][\"description\"] = \"Page number where the answer can be found, fill in with 0 if you couldn't find it\"\n",
    "\n",
    "        return schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults(persist_dir=\"./index/pdf\")\n",
    "index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.output_parsers import PydanticOutputParser\n",
    "\n",
    "input_component = InputComponent()\n",
    "output_parser = PydanticOutputParser(AnswerFormat)\n",
    "prompt_str = \"\"\"\\\n",
    "You are given a context with course materials in pdf files format, and you have access to these file's names, page numbers, and the content of the files. \n",
    "The file name is displayed at the beginning of every context chunk, and the page number is displayed as a integer number at the end of every page, and pages are separated by a dashed line.\n",
    "Answer the following questions: {query_str}\n",
    "And then find the file name and page number where the answer is mentioned.\n",
    "\"\"\"\n",
    "json_prompt_str = output_parser.format(prompt_str)\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.2,\n",
    ")\n",
    "retriever = index.as_retriever(similarity_top_k=10)\n",
    "reranker = ColbertRerank(top_n=3)\n",
    "DEFAULT_CONTEXT_PROMPT = json_prompt_str + (\n",
    "    \"Here is some context that may be relevant:\\n\"\n",
    "    \"-----\\n\"\n",
    "    \"{node_context}\\n\"\n",
    "    \"-----\\n\"\n",
    ")\n",
    "output_parser = PydanticOutputParser(AnswerFormat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are given a context with course materials in pdf files format, and you have access to these file's names, page numbers, and the content of the files. \n",
      "The file name is displayed at the beginning of every context chunk, and the page number is displayed as a integer number at the end of every page, and pages are separated by a dashed line.\n",
      "Answer the following questions: {query_str}\n",
      "And then find the file name and page number where the answer is mentioned.\n",
      "\n",
      "\n",
      "\n",
      "Here's a JSON schema to follow:\n",
      "{{\"description\": \"Object representing a single knowledge pdf file.\", \"properties\": {{\"answer\": {{\"default\": \"None\", \"title\": \"Answer\", \"type\": \"string\", \"description\": \"Your Answer to the given query\"}}, \"file_name\": {{\"default\": \"None\", \"title\": \"File Name\", \"type\": \"string\", \"description\": \"PDF file's file name where the answer can be found, fill in with empty string if you couldn't find it\"}}, \"page_number\": {{\"default\": 0, \"title\": \"Page Number\", \"type\": \"integer\", \"description\": \"Page number where the answer can be found, fill in with 0 if you couldn't find it\"}}}}, \"title\": \"AnswerFormat\", \"type\": \"object\"}}\n",
      "\n",
      "Output a valid JSON object but do not repeat the schema.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(json_prompt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are given a context with course materials in pdf files format, and you have access to these file's names, page numbers, and the content of the files. \n",
      "The file name is displayed at the beginning of every context chunk, and the page number is displayed as a integer number at the end of every page, and pages are separated by a dashed line.\n",
      "Answer the following questions: {query_str}\n",
      "And then find the file name and page number where the answer is mentioned.\n",
      "\n",
      "\n",
      "\n",
      "Here's a JSON schema to follow:\n",
      "{{\"description\": \"Object representing a single knowledge pdf file.\", \"properties\": {{\"answer\": {{\"default\": \"None\", \"title\": \"Answer\", \"type\": \"string\", \"description\": \"Your Answer to the given query\"}}, \"file_name\": {{\"default\": \"None\", \"title\": \"File Name\", \"type\": \"string\", \"description\": \"PDF file's file name where the answer can be found, fill in with empty string if you couldn't find it\"}}, \"page_number\": {{\"default\": 0, \"title\": \"Page Number\", \"type\": \"integer\", \"description\": \"Page number where the answer can be found, fill in with 0 if you couldn't find it\"}}}}, \"title\": \"AnswerFormat\", \"type\": \"object\"}}\n",
      "\n",
      "Output a valid JSON object but do not repeat the schema.\n",
      "Here is some context that may be relevant:\n",
      "-----\n",
      "{node_context}\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(DEFAULT_CONTEXT_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Response(CustomQueryComponent):\n",
    "    llm: OpenAI = Field(..., description=\"OpenAI LLM\")\n",
    "    system_prompt: Optional[str] = Field(\n",
    "        default=None, description=\"System prompt to use for the LLM\"\n",
    "    )\n",
    "    context_prompt: str = Field(\n",
    "        default=DEFAULT_CONTEXT_PROMPT,\n",
    "        description=\"Context prompt to use for the LLM\",\n",
    "    )\n",
    "\n",
    "    def _validate_component_inputs(\n",
    "        self, input: Dict[str, Any]\n",
    "    ) -> Dict[str, Any]:\n",
    "        return input\n",
    "\n",
    "    @property\n",
    "    def _input_keys(self) -> set:\n",
    "        # Removed \"chat_history\" from the input keys\n",
    "        return {\"nodes\", \"query_str\"}\n",
    "\n",
    "    @property\n",
    "    def _output_keys(self) -> set:\n",
    "        return {\"response\"}\n",
    "\n",
    "    def _prepare_context(\n",
    "        self,\n",
    "        # Removed chat_history parameter\n",
    "        nodes: List[NodeWithScore],\n",
    "        query_str: str,\n",
    "    ) -> List[ChatMessage]:\n",
    "        node_context = \"\"\n",
    "        for idx, node in enumerate(nodes):\n",
    "            node_text = node.get_content(metadata_mode=\"llm\")\n",
    "            node_context += f\"Context Chunk {idx}:\\n{node_text}\\n\\n\"\n",
    "\n",
    "        formatted_context = self.context_prompt.format(\n",
    "            node_context=node_context, query_str=query_str\n",
    "        )\n",
    "        user_message = ChatMessage(role=\"user\", content=formatted_context)\n",
    "\n",
    "        # print(formatted_context)\n",
    "\n",
    "        # Removed appending to chat_history\n",
    "        context = [user_message]\n",
    "\n",
    "        if self.system_prompt is not None:\n",
    "            # Adjusted to use context instead of chat_history\n",
    "            context = [\n",
    "                ChatMessage(role=\"system\", content=self.system_prompt)\n",
    "            ] + context\n",
    "\n",
    "        return context\n",
    "\n",
    "    def _run_component(self, **kwargs) -> Dict[str, Any]:\n",
    "        # Removed chat_history from kwargs\n",
    "        nodes = kwargs[\"nodes\"]\n",
    "        query_str = kwargs[\"query_str\"]\n",
    "\n",
    "        prepared_context = self._prepare_context(\n",
    "            # Adjusted call to _prepare_context\n",
    "            nodes, query_str\n",
    "        )\n",
    "        \n",
    "        response = self.llm.chat(prepared_context)\n",
    "        print(prepared_context)\n",
    "        return {\"response\": response}\n",
    "\n",
    "    async def _arun_component(self, **kwargs: Any) -> Dict[str, Any]:\n",
    "        # Removed chat_history from kwargs\n",
    "        nodes = kwargs[\"nodes\"]\n",
    "        query_str = kwargs[\"query_str\"]\n",
    "\n",
    "        prepared_context = self._prepare_context(\n",
    "            # Adjusted call to _prepare_context\n",
    "            nodes, query_str\n",
    "        )\n",
    "\n",
    "        response = await self.llm.achat(prepared_context)\n",
    "\n",
    "        return {\"response\": response}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_component = Response(\n",
    "    llm=llm,\n",
    "    system_prompt=(\n",
    "        \"You are a Q&A system. You will be provided with the previous chat history, \"\n",
    "        \"as well as possibly relevant context, to assist in answering a user message.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def pretty_print(df):\n",
    "    return display(HTML(df.to_html().replace(\"\\\\n\", \"<br>\")))\n",
    "\n",
    "def visualize_retrieved_nodes(nodes) -> None:\n",
    "    result_dicts = []\n",
    "    for node in nodes:\n",
    "        result_dict = {\"Score\": node.score, \"Text\": node.node.get_text()}\n",
    "        result_dicts.append(result_dict)\n",
    "\n",
    "    pretty_print(pd.DataFrame(result_dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = QueryPipeline(\n",
    "    modules={\n",
    "        \"input\": input_component,\n",
    "        \"query_retriever\": retriever,\n",
    "        \"reranker\": reranker,\n",
    "        \"response_component\": response_component,\n",
    "        \"output_parser\": output_parser\n",
    "    },\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "pipeline.add_link(\"input\", \"query_retriever\", src_key=\"query_str\")\n",
    "pipeline.add_link(\"query_retriever\", \"reranker\", dest_key=\"nodes\")\n",
    "pipeline.add_link(\n",
    "    \"input\", \"reranker\", src_key=\"query_str\", dest_key=\"query_str\"\n",
    ")\n",
    "pipeline.add_link(\"reranker\", \"response_component\", dest_key=\"nodes\")\n",
    "pipeline.add_link(\"input\", \"response_component\", dest_key=\"query_str\")\n",
    "pipeline.add_link(\"response_component\", \"output_parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module input with input: \n",
      "query_str: What is the first lecture about?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module query_retriever with input: \n",
      "input: What is the first lecture about?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module reranker with input: \n",
      "query_str: What is the first lecture about?\n",
      "nodes: [NodeWithScore(node=TextNode(id_='fabd5f98-a782-4c1d-beff-910648178d11', embedding=None, metadata={'filename': 'L01-f23.pdf', 'category': 'PDF file'}, excluded_embed_metadata_keys=[], excluded_llm_met...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module response_component with input: \n",
      "query_str: What is the first lecture about?\n",
      "nodes: [NodeWithScore(node=TextNode(id_='d70fab61-c911-49f4-8d64-8d81f893f1a2', embedding=None, metadata={'filename': 'L24-f23.pdf', 'category': 'PDF file'}, excluded_embed_metadata_keys=[], excluded_llm_met...\n",
      "\n",
      "\u001b[0m[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, content='You are a Q&A system. You will be provided with the previous chat history, as well as possibly relevant context, to assist in answering a user message.', additional_kwargs={}), ChatMessage(role=<MessageRole.USER: 'user'>, content='You are given a context with course materials in pdf files format, and you have access to these file\\'s names, page numbers, and the content of the files. \\nThe file name is displayed at the beginning of every context chunk, and the page number is displayed as a integer number at the end of every page, and pages are separated by a dashed line.\\nAnswer the following questions: What is the first lecture about?\\nAnd then find the file name and page number where the answer is mentioned.\\n\\n\\n\\nHere\\'s a JSON schema to follow:\\n{\"description\": \"Object representing a single knowledge pdf file.\", \"properties\": {\"answer\": {\"default\": \"None\", \"title\": \"Answer\", \"type\": \"string\", \"description\": \"Your Answer to the given query\"}, \"file_name\": {\"default\": \"None\", \"title\": \"File Name\", \"type\": \"string\", \"description\": \"PDF file\\'s file name where the answer can be found, fill in with empty string if you couldn\\'t find it\"}, \"page_number\": {\"default\": 0, \"title\": \"Page Number\", \"type\": \"integer\", \"description\": \"Page number where the answer can be found, fill in with 0 if you couldn\\'t find it\"}}, \"title\": \"AnswerFormat\", \"type\": \"object\"}\\n\\nOutput a valid JSON object but do not repeat the schema.\\nHere is some context that may be relevant:\\n-----\\nContext Chunk 0:\\nfilename: L24-f23.pdf\\ncategory: PDF file\\n\\n0  EeSA2\\n   Lecture 24: Internet and Cloud\\n                                 EE542\\n   Lecture 24: Internet and Cloud\\n   Internet and Cloud Computing\\n   Young Cho\\n   Department of Electrical Engineering\\n   University of Southern California\\n\\n\\n                                      6/13/2024Internet and Cloud Computing 1\\n---\\nIntemet Securtty Hbstoryy\\n Internet Security History\\n\\n\\n  \\uf097 Robert Tappan Morris\\n      ◦ Launched a worm (grad student at Cornell) that had a major impact\\n      ◦ Application designed to count the number of systems on the Internet\\n          \\uf096 a conceptual flaw in how rlogin, rsh, and rexec authenticate connections\\n          \\uf096 the archaic remote debug feature in Sendmail\\n          \\uf096 a buffer overflow in the finger daemon\\n          \\uf096 the Worm attempted far more propagation attempts than were necessary,\\n             causing targeted machines to slow dramatically from resource starvation\\n      ◦ He was arrested, found guilty, and sentenced\\n          \\uf096 400 hours of community service\\n          \\uf096 Fine of $10,050\\n  \\uf097 Today\\n      ◦ Tenured Professor at MIT\\n      ◦ Co-founder of a venture incubator (Y-Combinator)\\n\\n\\n                                               6/13/2024 Cho                          2\\n---\\n\\uf097 David L. SmithInternet Security History\\n    ◦ Melissa Worm recognized on 03/26/1999\\n    ◦ First major mail worm\\n    ◦ Word macro virus – attacked Microsoft’s\\n       Outlook and Word programs (semi-active)\\n        \\uf096 First 50 addresses in the recipients’ address book\\n        \\uf096 Shut down Internet mail systems that got clogged\\n           with infected e-mails\\n    ◦ Received a 10 year sentence\\n    ◦ Reduced to 20 month prison sentence and $5000\\n       fine by working for FBI\\n\\uf097 Today\\n    ◦ Catching perpetrators of internet-related crimes\\n\\n\\n                                                 6/13/2024 Cho  3\\n---\\nInternet Security History\\n\\n\\n\\uf097 Code Red (2001)\\n   ◦ exploited buffer overflow attack in Microsoft\\'s\\n      Internet Information Server\\n   ◦ Very quickly spreading\\n   ◦ 2nd version scanned logically adjacent IP addr\\n\\uf097 Nimda (2001)\\n   ◦ E-mail worm\\n   ◦ Bug in Explorer and Outlook\\n   ◦ spread through Windows shares, and an old buffer\\n      overflow in IIS\\n\\n\\n                                  6/13/2024 Cho        4\\n---\\nEsumated Financhl Damases\\nEstimated Financial Damages\\n\\n\\n \\uf097 Morris, 1988 - 60,000 computers - $10 to $100M damage\\n \\uf097 VBS/Loveletter, 2000 - $5.5B damage\\n \\uf097 Code Red, 2001 - $2.6B damage\\n \\uf097 Nimda, 2001 - $635B damage.\\n \\uf097 SQL Slammer, 2003 -150-200k computers\\n \\uf097 MS Blaster, 2003 - DoS (denial-of-service)\\n \\uf097 MyDoom, 2004 - distributed DoS attack with 1M infected\\n    machines\\n \\uf097 Witty, 2004 – limited damage but demonstrated that a worm could\\n    affect a population of machines and networks whose administrators\\n    were actively taking steps to improve security.\\n \\uf097 Today??? Multiple Billions with No Clear Solution\\n\\n\\n                                      6/13/2024 Cho                    5\\n---\\n  Cybercrime Expected To\\n  Skyrocket in the Coming Years\\n   Estimated cost of cybercrime worldwide\\n   (in trillion U.S. dollars)                                         23.82\\n                                                               20.74\\n                                                       17.65\\n                                               14.57\\n                                       11.50\\n                                8.44\\n                        5.99\\n                 2.95\\n 0.86    1.16\\n 2018    2019   2020    2021    2022    2023   2024    2025    2026    2027\\nAs of November 2022. Data shown is using current exchange rates.\\nSources: Statista Technology Market Outlook,\\nNational Cyber Security Organizations, FBI, IMF\\n                                                        statista\\n                                           6/13/2024 Internetworking and Dist. Systems  6\\n---\\n       Problem\\n        Problem\\n\\n\\n      \\uf097 Traditional Firewalls\\n          ◦ Only examine packet headers\\n      \\uf097 Current Attacks\\n          ◦ Embedded in the packet payload\\n      \\uf097 No Fixed Pattern for Emerging Attacks\\n\\n\\n                                   NO FTP\\n            TCP/IP\\n                  TCP/IP\\n                        port:21UDP\\nCode Red Worm                      NO UDP\\n\\n\\n                            Traditional Firewall\\n\\nContext Chunk 1:\\nfilename: L19-f23.pdf\\ncategory: PDF file\\n\\nR.10   0\\n                                                     0      M\\n                                   Young H. Cho, Ph.D.\\n                                   University of Southern California\\n                                    EE 542\\n                                    Lecture 19: Machine Learning\\nUSCViterbi\\n            School of Engineering                      Universityof Southern California\\n                                                                                     1\\n---\\n                        Final Project Proposal\\n\\n\\n• Requirement\\n     – xDot + Gateway + Node Red Data collection\\n     – Amazon Web Services + Thingsboard\\n     – Data Analytics/Machine Learning on Data\\n     – Inferential or Model-based Result\\n     – Real world problem that needs solution\\n     – Novel solution\\n• Submissions\\n     – Final Project Proposal: Summary Outline, Oct 25\\n     – Final Project Progress Videos\\n     – Final Project: Final Report, Software Source Package, Slides,\\n        Final video Due Dec 13\\n\\n\\n                                                                      2\\n---\\n                     Final Project Presentation\\n\\n\\n• Audience\\n     – Investor/Board of Directors/CEO\\n     – Grand parents/People without expertise\\n     – Technology Expert\\n• Composition\\n     – Attention Grab/Relevance/Problem to Investor+People without\\n        expertise\\n     – Most important/novel aspect using a detailed example\\n     – Summary of Result showing Supriority\\n     – Summary of what that means: Money? Safety? Good?\\n• Methodology\\n     – Use of Animations and Pictures\\n     – Minimum Words\\n     – Practiced Talk\\n\\n\\n                                                                    3\\n---\\n           Common Myths of Machine Learning\\n\\n\\n• Myth#1: Machines can learn autonomously\\n• Reality: Machine learning is carefully\\n   architected by a programmer and trained with\\n   the necessary training data. Most of the\\n   machine learning algorithms require large\\n   amounts of structured data that are often\\n   manually filtered and fed into the algorithm.\\n\\n\\n                                                  4\\n---\\n           Common Myths of Machine Learning\\n\\n\\n• Myth#2: Machines can learn like humans\\n• Reality: If we compare the learning process of a\\n   machine with that of a child, it becomes\\n   evident that machine learning is still in its\\n   infancy. For example, a baby doesn’t need to\\n   listen to millions of other humans before it\\n   learns how to talk. Machines on the other hand\\n   requires guidance and support at each step of\\n   learning.\\n\\n\\n                                                    5\\n---\\n              Common Myths of Machine Learning\\n\\n\\n• Myth#3: Machine learning can be applied to any task\\n• Reality: Currently, machine learning can only be\\n   applied to tasks where large and sufficient number\\n   of input data sets exist or can potentially be\\n   captured. Most of the successes in AI have come in\\n   the applications where companies like Google and\\n   Facebook have access to enormous data sets (texts,\\n   voices or images) coming from a variety of sources.\\n\\n\\n                                                        6\\n---\\n                 Traditional Data AnalyticsCurrent ML Approach\\n\\n\\n               Domain                          Data Collection\\n             KnowledgeDomainDomain                (Sensors)\\n              KnowledgeKnowledgeDomain\\n                Knowledge                       Preprocessor\\n                                                   (Filters)\\n• MODEL?!?                                         Model\\n     – Physics is too complex                     (Physics)\\n     – Insufficient understanding\\n     – Non-trivial correlation                  Classification\\n       between data and model                     (Metrics)\\n\\n\\n                                                                7\\n---\\n             My Thoughts\\n\\n\\n  Domain\\n  Domain                      Data Collection\\n                                             Data Collection\\nKnowledge\\nKnowledgeDomain\\n               DomainDomain\\n    Domain                       (Sensors)\\n                                          (Sensors)\\n Knowledge\\n          KnowledgeKnowledge\\n  KnowledgeDomain\\n     Domain\\n   Knowledge\\n   Knowledge                   Preprocessor\\n                                  (Filters)\\n\\n\\n                                   Model\\n                                        Model\\n                                 (Physics)\\n                                          (Physics)\\n\\n\\n                               Classification\\n                                 (Metrics)\\n\\n\\n                                                       8\\n---\\n            Machine Learning Approaches\\n\\n\\n                Unsupervised              Supervised\\n                   Learning                Learning\\n\\n\\n  Discrete         Clustering            Classification\\n\\n\\nContinuous      Dimensionality            Regression\\n                   Reduction\\n\\n\\n                                                         9\\n---\\n           Unsupervised Learning Experience\\n\\n\\n• Goal: Determine Meaning of Internet Document\\n   Content then Hierarchically and Dynamically\\n   Cluster and Discover New Topics using Hardware\\n   Accelerator\\n\\n\\n• Application: Discovering and Filter Topics of\\n   Interest on the Internet in Real-time\\n\\n\\n• Funded by US Department of Defense 2004-2007\\n\\n\\n                                                   10\\n---\\n              Processing Raw Documents\\n\\n\\n• N-Gram Analysis\\n    – Samples taken at every byte offset\\n    – Multiple lengths of n-grams sampled\\n\\n\\n                    FPGAs\\n                         FPGAs\\n                              FPGAs aar\\n                                       FPGAss arare\\n                                                   FPGAs arePGAs are\\n                                                                    PGAs\\n                                                                        PGAs\\n                                                                            PGAsGAs\\n                                                                                   GAs a\\n                                                                                        GAsaAs a\\n                                                                                                As ar\\n\\n\\n                                                             11\\n---\\n                 Language Identification\\n\\nContext Chunk 2:\\nfilename: L01-f23.pdf\\ncategory: PDF file\\n\\n0   63542\\n    EE542\\n   Loculro I:Intodctbn\\n    Lecture 1: Introduction\\n    Internet and Cloud Computing\\n\\n\\n    Young Cho\\n    Department of Electrical Engineering\\n    University of Southern California\\n\\n\\n                                          1\\n---\\nGoals\\n Goals\\n\\n\\n  \\uf097 Internet\\n      ◦ Computer Networking\\n      ◦ Internet protocols\\n      ◦ Network Security\\n      ◦ Networking Applications\\n  \\uf097 Cloud Computing\\n      ◦ Networked Computers\\n      ◦ Parallel Computers\\n      ◦ Internet of Things\\n      ◦ Big Data Analytics\\n      ◦ Artificial Intelligence and Machine Learning\\n      ◦ Hardware Accelerated Processing\\n  \\uf097 No Time to Waste\\n\\n\\n                                             6/13/2024  2\\n---\\nLeststs\\n Logistics\\n\\n\\n  \\uf097 Lectures\\n      ◦ Mondays and Wednesday\\n  \\uf097 Assignments\\n      ◦ Paper Reading (Slide Submissions)\\n      ◦ Laboratory Assignments (Reports, Forum Posts, and Demos)\\n      ◦ Final Project (Report, Presentation, and Demo)\\n  \\uf097 Instructor:Young Cho\\n  \\uf097 Teaching Assistants: Yude Wei and Haonan Wang\\n  \\uf097 Web Sites\\n      ◦ Blackboard\\n      ◦ Amazon Web Services\\n\\n\\n                                           6/13/2024              3\\n---\\nCourso Syllabus\\nCourse Syllabus\\n\\n\\n \\uf097 Attendance\\n \\uf097 Reading List\\n \\uf097 Laboratory Assignments\\n \\uf097 Final Project\\n   ◦ Final Project Pitch\\n   ◦ Final Report\\n\\n\\n                           6/13/2024  4\\n---\\nFrokectProject\\n\\n\\n  \\uf097 Laboratory Assignment\\n     ◦ Individual or Team\\n     ◦ Youtube Video Recordings\\n  \\uf097 Tools\\n     ◦ VirtualBox\\n     ◦ Amazon Web Services or others\\n     ◦ Linux network API (sockets, pcap lib, and etc.)\\n\\n\\n                               6/13/2024                5\\n---\\nPerepectie\\n Perspective\\n\\n\\n  \\uf097 A Huge Domain\\n  \\uf097 Main Topics\\n     ◦ New Directions on Internet\\n     ◦ Machine Learning on Cloud\\n  \\uf097 Methodology\\n     ◦ Protocol Design\\n     ◦ Internet of Things\\n     ◦ Machine Learning\\n  \\uf097 How to not waste time\\n     ◦ Work on your own research\\n     ◦ Publish a paper?!\\n\\n\\n                                   6/13/2024  6\\n---\\nThe Internet\\nThe Internet\\n\\n\\n \\uf097 Computer Networks\\n    ◦ Network interfaces\\n    ◦ Switches\\n    ◦ Routers\\n    ◦ Firewalls and etc…\\n \\uf097 Software\\n    ◦ Network protocols\\n    ◦ Operating System interface\\n    ◦ Application level interface\\n \\uf097 Hardware\\n    ◦ Lightweight microprocessors\\n    ◦ Hardware accelerators\\n    ◦ Network processors\\n\\n\\n                                   6/13/2024  7\\n---\\nComputer Network\\n Computer Network\\n\\n\\n                                       H3\\n                    3I\\n     H1\\n                                R4\\n                R2\\n                         R3\\n                                       R6\\n                      R5                   H4\\n               H2\\n                     Destination Next Hop\\n                     H1     R3\\n                     H3     R3\\n                     H4     R6\\n\\n\\n                         6/13/2024             8\\n---\\nComputer Network Hardara\\n Computer Network Hardware\\n\\n\\n                   6/13/2024  9\\n---\\nOpen Syatem Intonconnectkon\\n Open System Interconnection\\n                                         O5I MODEL\\n                                          ApplicationLuyel\\n                                                   mnmunication:\\n                                          cliertsery_transter\\n                               6          presentation Luyel\\n                                                       2corverslor\\n                                                binary, etc_\\n                              5           Session Layer\\n                                          Starts_Sop:Spssior\\n                                          Maintains order _\\n                               4         Fesoresdelivery\\n                                                        Transport Layer\\n                                                            ertire\\n                                             Or Message\\n                               3          Iletwork Layer\\n                                          Routes datato differert\\n                                          LANsand WANs basednetwyorkaddress\\n                               2  mo =O  Data Link (MACI Layer\\n                                          Transmits packetsfrom\\n                                         nodetonodeDased\\n                                          sation address                9\\n                                          Physical Layer\\n                                          Flectricssignals anocabling\\n                                                                             From computer desktop\\n                                                                             encyclopedia © 2004\\n\\n\\n                                              6/13/2024                                             10\\n---\\n         Internet Protocol\\n          Internet Protocol\\n\\n\\nProblem: Network Overload\\n\\n\\nSolution: Buffering and Congestion Control\\n     \\uf097 Short bursts: buffer\\n     \\uf097 What if buffer overflows?\\n        ◦ Packets dropped\\n        ◦ Sender adjusts rate until load = resources → “congestion control”\\n\\n\\n-----\\n', additional_kwargs={})]\n",
      "\u001b[1;3;38;2;155;135;227m> Running module output_parser with input: \n",
      "input: assistant: ```json\n",
      "{\n",
      "  \"answer\": \"The first lecture is about an introduction to Internet and Cloud Computing.\",\n",
      "  \"file_name\": \"L01-f23.pdf\",\n",
      "  \"page_number\": 1\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = pipeline.run(query_str=\"What is the first lecture about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnswerFormat(answer='The first lecture is about an introduction to Internet and Cloud Computing.', file_name='L01-f23.pdf', page_number=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "\n",
    "net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n",
    "net.from_nx(pipeline.dag)\n",
    "net.show(\"rag_dag.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coursistant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
