{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core.memory import ChatMemoryBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults(persist_dir=\"../index/pdf\")\n",
    "index = load_index_from_storage(storage_context)\n",
    "memory = ChatMemoryBuffer.from_defaults(token_limit=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As Chat Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_engine = index.as_chat_engine(\n",
    "    chat_mode=\"context\",\n",
    "    memory=memory,\n",
    "    system_prompt=(\n",
    "        \"You are a chatbot assistant helping a user with their questions. \"\n",
    "        \"You are only allowed to provide information that is inside the context given to you. \"\n",
    "        \"The context given is the pdf files of lecture slides. You are given the metadata of the pdf files. \"\n",
    "        \"First answer the user's question, then provide the file name where the answer can be found. \"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hi, what is this course about?\n",
      "Bot: This course covers topics related to the Internet and Cloud Computing, including computer networking, Internet protocols, network security, networking applications, networked computers, parallel computers, Internet of Things, big data analytics, artificial intelligence, machine learning, and hardware accelerated processing.\n",
      "\n",
      "You can find more details in the file \"63542_EE542_Lecture1_Introduction_Internet_and_Cloud_Computing.pdf\".\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input == \"quit\":\n",
    "        break\n",
    "    print(\"User:\", user_input)\n",
    "    response = chat_engine.chat(user_input)\n",
    "    print(\"Bot:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  what is this course about?\n",
      "Bot: The course is about providing advice and guidance on how to navigate a graduate career successfully. It covers topics such as concentrating on learning rather than just graduating quickly, the importance of attending conferences, the value of polishing writing and presentations, managing workload effectively, gaining industrial experience, taking bold chances on challenging topics, and the significance of self-driven learning and teaching.\n",
      "User: What is the course number of this course?\n",
      "Bot: The course number of this course is 56.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input == \"quit\":\n",
    "        break\n",
    "    print(\"User:\", user_input)\n",
    "    response = query_engine.query(user_input)\n",
    "    print(\"Bot:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_response(query):\n",
    "#     # Retrieve the answer and metadata from LlamaIndex\n",
    "#     answer, metadata = llama_index_query_engine.query(query)\n",
    "    \n",
    "#     # Format the response to include the file name\n",
    "#     response = f\"The answer is: {answer}\\nFound in file: {metadata['file_name']}\"\n",
    "#     return response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
